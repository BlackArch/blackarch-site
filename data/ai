adversarial-robustness-toolbox|1.20.1.r155.g23539e2|Python Library for Machine Learning Security.|https://github.com/Trusted-AI/adversarial-robustness-toolbox
cai|0.5.9.r0.g96aff0d|The framework for AI Security.|https://github.com/aliasrobotics/cai
cleverhans|v4.0.0.r7.g574efc1|Python library to benchmark machine learning systems vulnerability to adversarial examples.|https://github.com/cleverhans-lab/cleverhans
